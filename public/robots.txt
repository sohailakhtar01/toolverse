# Robots.txt for TheToolsVerse.com - AI Tools Directory
# Updated: September 2025

# Default crawling permissions for all bots
User-agent: *
Allow: /

# Block problematic URLs that cause 404s
Disallow: /products/
Disallow: /product/
Disallow: /shop/
Disallow: /cart/
Disallow: /checkout/

# Block technical and admin directories
Disallow: /api/
Disallow: /admin/
Disallow: /_next/
Disallow: /studio/
Disallow: /.well-known/
Disallow: /static/

# Block search and dynamic parameters
Disallow: /*?*
Disallow: /*&*

# Block specific file types that might cause issues
Disallow: /*.json$
Disallow: /*.xml$ 
# Note: This will block XML files but sitemap.xml is explicitly allowed below

# Allow important sitemaps (override the XML block above)
Allow: /sitemap.xml
Allow: /sitemap*.xml

# Crawl delay for server load management
Crawl-delay: 1

# Sitemap location
Sitemap: https://www.thetoolsverse.com/sitemap.xml